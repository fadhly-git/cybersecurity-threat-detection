{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.models.ml_models import MLModels\n",
    "from src.models.dl_models import DLModels\n",
    "from src.evaluation.metrics import ModelEvaluator\n",
    "from src.evaluation.visualization import Visualizer\n",
    "from src.utils.helpers import load_config\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ea184",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "X_train = np.load('../data/processed/X_train.npy')\n",
    "X_test = np.load('../data/processed/X_test.npy')\n",
    "y_train = np.load('../data/processed/y_train.npy')\n",
    "y_test = np.load('../data/processed/y_test.npy')\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5699a39a",
   "metadata": {},
   "source": [
    "## üå≤ 1. Train Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2444718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ML models\n",
    "ml_models = MLModels()\n",
    "\n",
    "# Dictionary to store results\n",
    "ml_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a74f78",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Random Forest...\")\n",
    "\n",
    "# Build model\n",
    "rf_model = ml_models.build_random_forest(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "\n",
    "# Train with cross-validation\n",
    "rf_trained, rf_cv_scores = ml_models.train_model(\n",
    "    rf_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    use_cv=True,\n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "# Predict\n",
    "rf_pred, rf_pred_proba = ml_models.predict(rf_trained, X_test)\n",
    "\n",
    "print(f\"CV Accuracy: {np.mean(rf_cv_scores):.4f} (+/- {np.std(rf_cv_scores):.4f})\")\n",
    "print(f\"Test Accuracy: {(rf_pred == y_test).mean():.4f}\")\n",
    "\n",
    "ml_results['Random Forest'] = {\n",
    "    'model': rf_trained,\n",
    "    'predictions': rf_pred,\n",
    "    'probabilities': rf_pred_proba,\n",
    "    'cv_scores': rf_cv_scores\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f5181b",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef72fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training SVM...\")\n",
    "\n",
    "svm_model = ml_models.build_svm(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale'\n",
    ")\n",
    "\n",
    "svm_trained, svm_cv_scores = ml_models.train_model(\n",
    "    svm_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    use_cv=True,\n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "svm_pred, svm_pred_proba = ml_models.predict(svm_trained, X_test)\n",
    "\n",
    "print(f\"CV Accuracy: {np.mean(svm_cv_scores):.4f} (+/- {np.std(svm_cv_scores):.4f})\")\n",
    "print(f\"Test Accuracy: {(svm_pred == y_test).mean():.4f}\")\n",
    "\n",
    "ml_results['SVM'] = {\n",
    "    'model': svm_trained,\n",
    "    'predictions': svm_pred,\n",
    "    'probabilities': svm_pred_proba,\n",
    "    'cv_scores': svm_cv_scores\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138bea7",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ffd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training XGBoost...\")\n",
    "\n",
    "xgb_model = ml_models.build_xgboost(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "xgb_trained, xgb_cv_scores = ml_models.train_model(\n",
    "    xgb_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    use_cv=True,\n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "xgb_pred, xgb_pred_proba = ml_models.predict(xgb_trained, X_test)\n",
    "\n",
    "print(f\"CV Accuracy: {np.mean(xgb_cv_scores):.4f} (+/- {np.std(xgb_cv_scores):.4f})\")\n",
    "print(f\"Test Accuracy: {(xgb_pred == y_test).mean():.4f}\")\n",
    "\n",
    "ml_results['XGBoost'] = {\n",
    "    'model': xgb_trained,\n",
    "    'predictions': xgb_pred,\n",
    "    'probabilities': xgb_pred_proba,\n",
    "    'cv_scores': xgb_cv_scores\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0d085",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f090acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Gradient Boosting...\")\n",
    "\n",
    "gb_model = ml_models.build_gradient_boosting(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "gb_trained, gb_cv_scores = ml_models.train_model(\n",
    "    gb_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    use_cv=True,\n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "gb_pred, gb_pred_proba = ml_models.predict(gb_trained, X_test)\n",
    "\n",
    "print(f\"CV Accuracy: {np.mean(gb_cv_scores):.4f} (+/- {np.std(gb_cv_scores):.4f})\")\n",
    "print(f\"Test Accuracy: {(gb_pred == y_test).mean():.4f}\")\n",
    "\n",
    "ml_results['Gradient Boosting'] = {\n",
    "    'model': gb_trained,\n",
    "    'predictions': gb_pred,\n",
    "    'probabilities': gb_pred_proba,\n",
    "    'cv_scores': gb_cv_scores\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3b23a",
   "metadata": {},
   "source": [
    "## üß† 2. Train Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797415fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DL models\n",
    "dl_models = DLModels()\n",
    "\n",
    "# Prepare data for DL (reshape for CNN/LSTM)\n",
    "input_shape = (X_train.shape[1], 1)\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Create validation split\n",
    "val_split = 0.2\n",
    "val_size = int(len(X_train) * val_split)\n",
    "X_train_dl = X_train[:-val_size]\n",
    "y_train_dl = y_train[:-val_size]\n",
    "X_val = X_train[-val_size:]\n",
    "y_val = y_train[-val_size:]\n",
    "\n",
    "print(f\"DL Training set: {X_train_dl.shape}\")\n",
    "print(f\"DL Validation set: {X_val.shape}\")\n",
    "\n",
    "# Dictionary to store DL results\n",
    "dl_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2968dc62",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63205b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building and training CNN...\")\n",
    "\n",
    "# Build CNN\n",
    "cnn_model = dl_models.build_cnn(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    filters=[64, 128, 256],\n",
    "    kernel_size=3,\n",
    "    dropout_rate=0.3\n",
    ")\n",
    "\n",
    "# Compile\n",
    "cnn_model = dl_models.compile_model(cnn_model, learning_rate=0.001)\n",
    "\n",
    "# Create callbacks\n",
    "cnn_callbacks = dl_models.create_callbacks(\n",
    "    model_name='CNN',\n",
    "    patience=10,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Train\n",
    "cnn_history = dl_models.train_model(\n",
    "    cnn_model,\n",
    "    X_train_dl,\n",
    "    y_train_dl,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=cnn_callbacks\n",
    ")\n",
    "\n",
    "dl_results['CNN'] = {\n",
    "    'model': cnn_model,\n",
    "    'history': cnn_history\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2674f5cd",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36149ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building and training LSTM...\")\n",
    "\n",
    "lstm_model = dl_models.build_lstm(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    lstm_units=[128, 64],\n",
    "    dropout_rate=0.3,\n",
    "    bidirectional=True\n",
    ")\n",
    "\n",
    "lstm_model = dl_models.compile_model(lstm_model, learning_rate=0.001)\n",
    "\n",
    "lstm_callbacks = dl_models.create_callbacks(\n",
    "    model_name='LSTM',\n",
    "    patience=10,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "lstm_history = dl_models.train_model(\n",
    "    lstm_model,\n",
    "    X_train_dl,\n",
    "    y_train_dl,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=lstm_callbacks\n",
    ")\n",
    "\n",
    "dl_results['LSTM'] = {\n",
    "    'model': lstm_model,\n",
    "    'history': lstm_history\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f94771",
   "metadata": {},
   "source": [
    "### VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc25515",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building and training VGG...\")\n",
    "\n",
    "vgg_model = dl_models.build_vgg(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    num_blocks=3,\n",
    "    filters_per_block=[64, 128, 256],\n",
    "    dropout_rate=0.3\n",
    ")\n",
    "\n",
    "vgg_model = dl_models.compile_model(vgg_model, learning_rate=0.001)\n",
    "\n",
    "vgg_callbacks = dl_models.create_callbacks(\n",
    "    model_name='VGG',\n",
    "    patience=10,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "vgg_history = dl_models.train_model(\n",
    "    vgg_model,\n",
    "    X_train_dl,\n",
    "    y_train_dl,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=vgg_callbacks\n",
    ")\n",
    "\n",
    "dl_results['VGG'] = {\n",
    "    'model': vgg_model,\n",
    "    'history': vgg_history\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e761d",
   "metadata": {},
   "source": [
    "### ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27783ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building and training ResNet...\")\n",
    "\n",
    "resnet_model = dl_models.build_resnet(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    num_blocks=3,\n",
    "    filters_per_block=[64, 128, 256],\n",
    "    dropout_rate=0.3\n",
    ")\n",
    "\n",
    "resnet_model = dl_models.compile_model(resnet_model, learning_rate=0.001)\n",
    "\n",
    "resnet_callbacks = dl_models.create_callbacks(\n",
    "    model_name='ResNet',\n",
    "    patience=10,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "resnet_history = dl_models.train_model(\n",
    "    resnet_model,\n",
    "    X_train_dl,\n",
    "    y_train_dl,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=resnet_callbacks\n",
    ")\n",
    "\n",
    "dl_results['ResNet'] = {\n",
    "    'model': resnet_model,\n",
    "    'history': resnet_history\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9baca",
   "metadata": {},
   "source": [
    "## üìä Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for all DL models\n",
    "visualizer = Visualizer()\n",
    "\n",
    "for model_name, result in dl_results.items():\n",
    "    print(f\"\\n{model_name} Training History:\")\n",
    "    visualizer.plot_training_history(\n",
    "        result['history'],\n",
    "        title=f'{model_name} Training History'\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bee149",
   "metadata": {},
   "source": [
    "## üéØ Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d6470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ML models\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "print(\"Machine Learning Models Performance:\\n\")\n",
    "ml_comparison = []\n",
    "\n",
    "for model_name, result in ml_results.items():\n",
    "    metrics = evaluator.calculate_metrics(\n",
    "        y_test,\n",
    "        result['predictions'],\n",
    "        result['probabilities']\n",
    "    )\n",
    "    ml_comparison.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1-Score': metrics['f1_score']\n",
    "    })\n",
    "\n",
    "ml_comparison_df = pd.DataFrame(ml_comparison)\n",
    "display(ml_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cefebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate DL models\n",
    "print(\"\\nDeep Learning Models Performance:\\n\")\n",
    "dl_comparison = []\n",
    "\n",
    "for model_name, result in dl_results.items():\n",
    "    # Get predictions\n",
    "    y_pred_proba = result['model'].predict(X_test.reshape(-1, X_test.shape[1], 1))\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    metrics = evaluator.calculate_metrics(y_test, y_pred, y_pred_proba)\n",
    "    dl_comparison.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1-Score': metrics['f1_score']\n",
    "    })\n",
    "\n",
    "dl_comparison_df = pd.DataFrame(dl_comparison)\n",
    "display(dl_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d0e284",
   "metadata": {},
   "source": [
    "## üíæ Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde77e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('../results/models/ml', exist_ok=True)\n",
    "os.makedirs('../results/models/dl', exist_ok=True)\n",
    "\n",
    "# Save ML models\n",
    "for model_name, result in ml_results.items():\n",
    "    filename = f\"../results/models/ml/{model_name.replace(' ', '_').lower()}.pkl\"\n",
    "    joblib.dump(result['model'], filename)\n",
    "    print(f\"Saved {model_name} to {filename}\")\n",
    "\n",
    "# Save DL models\n",
    "for model_name, result in dl_results.items():\n",
    "    filename = f\"../results/models/dl/{model_name.lower()}.h5\"\n",
    "    result['model'].save(filename)\n",
    "    print(f\"Saved {model_name} to {filename}\")\n",
    "\n",
    "print(\"\\n‚úÖ All models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231bf450",
   "metadata": {},
   "source": [
    "## üìù Summary\n",
    "\n",
    "### Trained Models:\n",
    "- ‚úÖ 4 Machine Learning models\n",
    "- ‚úÖ 4 Deep Learning models\n",
    "\n",
    "### Next Steps:\n",
    "1. Proceed to **04_results_visualization.ipynb** for comprehensive evaluation\n",
    "2. Analyze confusion matrices and ROC curves\n",
    "3. Compare all models\n",
    "4. Generate final report"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
